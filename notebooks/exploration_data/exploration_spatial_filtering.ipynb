{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration on spatial filtering\n",
    "\n",
    "This notebook is an exploration on spatial filtering. The goal is to understand how spatial filtering works and how it can be used to enhance images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyriemann in d:\\projects\\anaconda\\lib\\site-packages (0.5)\n",
      "Requirement already satisfied: joblib in d:\\projects\\anaconda\\lib\\site-packages (from pyriemann) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn in d:\\projects\\anaconda\\lib\\site-packages (from pyriemann) (1.2.1)\n",
      "Requirement already satisfied: scipy in d:\\projects\\anaconda\\lib\\site-packages (from pyriemann) (1.10.0)\n",
      "Requirement already satisfied: numpy!=1.24.0 in d:\\projects\\anaconda\\lib\\site-packages (from pyriemann) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\projects\\anaconda\\lib\\site-packages (from scikit-learn->pyriemann) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyriemann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration using techniques from BE_MI_Filled adapted to our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.preprocessing.train import process_train_data\n",
    "\n",
    "\n",
    "PATH_DATA_FOLDER = './data'\n",
    "PATH_DATA_RAW_FOLDER = f'{PATH_DATA_FOLDER}/raw'\n",
    "PATH_DATA_001_TRIAL1_FILE = f'{PATH_DATA_RAW_FOLDER}/DATA_001_Trial1.npy'\n",
    "\n",
    "\n",
    "array_001_t1 = np.load(PATH_DATA_001_TRIAL1_FILE, allow_pickle=True)\n",
    "side = 'G'\n",
    "fs = 1024\n",
    "low_freq = 10\n",
    "high_freq = 50\n",
    "epoch_start_time = -1\n",
    "epoch_end_time = 1\n",
    "window_size = 0.5\n",
    "step_size = 0.1\n",
    "pre_duration = 0.5\n",
    "post_duration = 0\n",
    "\n",
    "# TBD : Documentation MNE à lire : ICA, préprocessing, ... class MNE epochs, MNE\n",
    "# regarder et utiliser train.py de Julien : ICA pour denoising + BSS à faire pour travailler sur les sources (pas les électrodes)\n",
    "# xDawn en MNE : à checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labels, meta_data = process_train_data(array_mple_t1, side, fs, low_freq, high_freq, window_size, \n",
    "                                   step_size, epoch_start_time, epoch_end_time, pre_duration, post_duration, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import Epochs, find_events, pick_types\n",
    "\n",
    "def load_epoch(raws, subject_nb, event_id, fmin = 7., fmax = 35.):\n",
    "    \"\"\"Function to load epoched data for a specified subject\"\"\"\n",
    "    \n",
    "    raw = raws[subject_nb]['0']['0']\n",
    "\n",
    "    # Apply band-pass filter\n",
    "    raw.filter(fmin, fmax, fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    # Get the event (left / right hand) by looking at the \"stim\" channel.\n",
    "    events = find_events(raw, shortest_event=0, verbose=True)\n",
    "\n",
    "    picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "    tmin, tmax = -1., 4.\n",
    "    # Read epochs (train will be done only between 1 and 2s)\n",
    "    # Testing will be done with a running classifier\n",
    "    epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "    labels = epochs.events[:, -1] - 1\n",
    "    return epochs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pochs, labels = load_epoch(raws, event_id, 1, fmin=5., fmax = 50)\n",
    "epoch_train = epochs.crop(tmin=1., tmax=2.)\n",
    "\n",
    "# Convert from MNE object to numpy Nd-array\n",
    "epochs_data_train = epochs.get_data()\n",
    "\n",
    "# Assemble feature extractor \n",
    "cov = Covariances(estimator='scm')                                                      # HERE\n",
    "ts = TangentSpace()                                                                     # HERE\n",
    "ss = StandardScaler()                                                                   # HERE\n",
    "\n",
    "# Assemble a classifier\n",
    "rf = RandomForestClassifier()                                                           # HERE\n",
    "\n",
    "# Use scikit-learn Pipeline\n",
    "clf = Pipeline([('cov', cov), ('ts', ts), ('ss', ss), ('rf', rf)])                      # HERE\n",
    "\n",
    "# Evaluate the resulting classifier using cross-validation\n",
    "scores = cross_val_score(clf, epochs_data_train, labels, cv=10, n_jobs=1,verbose=False) # HERE\n",
    "print('Mean score:', np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
