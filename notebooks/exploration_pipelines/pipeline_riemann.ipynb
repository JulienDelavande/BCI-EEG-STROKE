{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Julien - Riemann projection (cov, ts, ss, estimator)\n",
    "\n",
    "## Introduction\n",
    "This notebook is a part of the project to compare the performance of different pipelines for EEG elbow movement classification. The goal of these notebooks is to establish a standard pipeline for EEG elbow movement classification. \n",
    "\n",
    "This notebook explores the performance of the riemann pipeline. The riemann pipeline is a standard pipeline for EEG classification. It is based on the riemannian geometry of covariance matrices. The pipeline is composed of 3 main steps:\n",
    "1. Feature extraction: Covariance matrices, tangent space projection, standard scaler\n",
    "2. Classification: Logistic regression, Linear discriminant analysis, Support vector machine, Random forest\n",
    "3. Evaluation: Balanced accuracy\n",
    "\n",
    "We also establised 4 tests to evaluate the performance of the pipeline in cross-validation:\n",
    "-  Tester A: Seen session / seen subject (but not the same data)\n",
    "-  Tester B: Unseen session / seen subject (but not the same data)\n",
    "-  Tester C: Unseen session / unseen subject\n",
    "-  Tester X: All epochs shuffled\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## Methodology\n",
    "In this notebook we aim to establish the performance of the rieman pipeline. Here are the steps we will follow:\n",
    "1. Preprocessing:\n",
    "    - Loading the data from each .npy file using Dataloader built for this project.\n",
    "    - Using only the session which record the movement of the arm oposite to stroke side. (REQUIREMENT)\n",
    "    - Using only the electrodes from the stroke side. (REQUIREMENT)\n",
    "    - Labeling the data using the acceleration (done in the dataloader, see ./notebooks/exploration_data/Labelling_data.ipynb for the exact process)\n",
    "    - Filtering the data between 1 and 40 Hz.\n",
    "    - Getting the train and test data by epoching around the movement onset. 1=extension 2=flexion 0=rest(or no onset to be precise) To get data labelled 0 we took epoch from 4s to 1s before movement onset.\n",
    "    - Relabelling extension and flexion as 1 and no onset as 0.\n",
    "2. Feature extraction:\n",
    "    -  Covariances matrices :\\\n",
    "    The first step involves computing the covariance matrix of EEG signals. Covariance measures how two variables change together. For EEG signals, this helps in understanding how different sensors (or channels) record signals that are correlated with each other. This is crucial for capturing spatial relationships among different EEG channels. Essentially, it's about finding patterns in how different parts of the brain signal together during different movements.\n",
    "    -  Tangent space features :\\\n",
    "     After computing the covariance matrices, they are often projected into a tangent space. The tangent space is a linear space that 'touches' a nonlinear surface (in this case, the space of covariance matrices) at a point. This linearization of covariance data, which can naturally be nonlinear and reside on a manifold (a curved surface in a higher-dimensional space), makes it easier to apply standard machine learning techniques, which generally perform better with linear data. Think of this step as a way to simplify and flatten complex, curved data into a more understandable and processable form.\n",
    "    -  Standard scaler :\\\n",
    "    Ensures that all features are equally weighted.\n",
    "3. Classification: (compared differents classifiers)\n",
    "    -  Logistic regression\n",
    "    -  Linear discriminant analysis\n",
    "    -  Support vector machine\n",
    "    -  Random forest\n",
    "4. Evaluation:\n",
    "    1. Evaluation on epoched data. Using balanced accuracy to evaluate the performance of the pipeline using 3 differents testers:\n",
    "        -  Tester 1: Seen session / seen subject (but not the same data)\n",
    "        -  Tester 2: Unseen session / seen subject (but not the same data)\n",
    "        -  Tester 3: Unseen session / unseen subject\n",
    "    2. Evaluation on continuous data. Using balanced accuracy to evaluate the performance of the pipeline using 3 differents testers:\n",
    "        -  Tester 1: Seen session / seen subject (but not the same data)\n",
    "        -  Tester 2: Unseen session / seen subject (but not the same data)\n",
    "        -  Tester 3: Unseen session / unseen subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_SESSIONS = 30\n",
    "\n",
    "# Fréquence de filtrage\n",
    "FMIN = 1\n",
    "FMAX = 40\n",
    "\n",
    "# Bornes époques\n",
    "EPOCHS_TMIN = -1\n",
    "EPOCHS_TMAX = 2\n",
    "\n",
    "# temps depuis le mouvement pour époquer autours d'une plage sans mouvement\n",
    "EPOCHS_EMPTY_FROM_MVT_TMINS = -4\n",
    "\n",
    "BINARY_CLASSIFICATION = True\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_SPLIT = 4\n",
    "\n",
    "FOLDER_PATH = './../../data/raw/Data_npy/'\n",
    "FILE_PATH_LIST = [FOLDER_PATH + file_path for file_path in os.listdir(FOLDER_PATH) if file_path.endswith('.npy')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels(raws, side):\n",
    "    endings = ('1', '3', '5', '7', '9') if side=='D' else ('2', '4', '6', '8', '10')\n",
    "    channels_to_remove = [channel for channel in raws.ch_names if channel.endswith(endings)]\n",
    "    channels = [channel for channel in raws.ch_names if channel not in channels_to_remove]\n",
    "    return channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def preproc(file_path_list, verbose=False):\n",
    "    # structure data_patients = [session1, session2, ...]            dtype = list\n",
    "    # structure data_session  = [epoch1, epoch2, ...]                dtype = np.array\n",
    "    # structure epoch         = np.array([channel1, channel2, ...])  dtype = np.array\n",
    "    # structure channel       = np.array([time1, time2, ...])        dtype = float\n",
    "\n",
    "    # structure labels_patients     = [session1, session2, ...]            dtype = list\n",
    "    # structure labels_session      = [label_epoch1, label_epoch2, ...]    dtype = int (0, 1, 2)\n",
    "\n",
    "    data_patients = []\n",
    "    labels_patients = []\n",
    "\n",
    "    patients_id = []\n",
    "    sessions_id = []\n",
    "\n",
    "    for file in tqdm.tqdm(file_path_list):\n",
    "\n",
    "        # loading data / auto labeling behind the scene\n",
    "        data_loader = DataLoader(file)\n",
    "\n",
    "        # picking the arm session opposite to the stroke side\n",
    "        stroke = data_loader.stroke_side\n",
    "        arm_side = 'G' if stroke == 'D' else 'G'\n",
    "        raws = data_loader.get_raws(side=arm_side)\n",
    "        \n",
    "        # if no data for the arm side, we skip the session\n",
    "        if raws is None:\n",
    "            continue\n",
    "\n",
    "        # picking channels of only the stroke side\n",
    "        raws.pick_channels(get_channels(raws, stroke))\n",
    "\n",
    "        # filtering\n",
    "        raws.filter(FMIN, FMAX, fir_design='firwin')\n",
    "\n",
    "        # creating epochs over flexion and extension of the arm (movement)\n",
    "        events = mne.find_events(raws, stim_channel=['movement'])\n",
    "        picks = mne.pick_types(raws.info, eeg=True, stim=False)\n",
    "        epochs = mne.Epochs(raws, events, tmin=EPOCHS_TMIN, tmax=EPOCHS_TMAX, picks=picks, baseline=None, preload=True)\n",
    "        epochs_data_mvt = epochs.get_data()\n",
    "        label_mvt = epochs.events[:, -1]\n",
    "\n",
    "        # creating artificial epoch when no movement\n",
    "        epochs_no_mvt = mne.Epochs(raws, events, tmin=EPOCHS_EMPTY_FROM_MVT_TMINS, tmax=EPOCHS_EMPTY_FROM_MVT_TMINS+EPOCHS_TMAX-EPOCHS_TMIN, \n",
    "                                    picks=picks, baseline=None, preload=True)\n",
    "        epochs_data_no_mvt = epochs_no_mvt.get_data()\n",
    "        labels_no_mvt = np.zeros(epochs_data_no_mvt.shape[0])\n",
    "\n",
    "        # concatenating epochs\n",
    "        epochs_data_session = np.concatenate((epochs_data_mvt, epochs_data_no_mvt), axis=0)\n",
    "        labels_session = np.concatenate((label_mvt, labels_no_mvt), axis=0)\n",
    "\n",
    "        # Shuffling epochs\n",
    "        random_state = np.random.RandomState(RANDOM_STATE)\n",
    "        indices = np.arange(epochs_data_session.shape[0])\n",
    "        random_state.shuffle(indices)\n",
    "        epochs_data_session = epochs_data_session[indices]\n",
    "        labels_session = labels_session[indices]\n",
    "\n",
    "        # if binary classification, we merge flexion and extension\n",
    "        if BINARY_CLASSIFICATION:\n",
    "            labels_session[labels_session != 0] = 1\n",
    "\n",
    "        # adding session data and session labels to data_patients and labels_patients (if new patient, add new list)\n",
    "        if data_loader.patient_id not in patients_id:\n",
    "            patients_id.append(data_loader.patient_id)\n",
    "            sessions_id.append([])\n",
    "            data_patients.append([])\n",
    "            labels_patients.append([])\n",
    "        sessions_id[patients_id.index(data_loader.patient_id)].append(data_loader.session_id)\n",
    "        data_patients[patients_id.index(data_loader.patient_id)].append(epochs_data_session)\n",
    "        labels_patients[patients_id.index(data_loader.patient_id)].append(labels_session)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'patient id: {data_loader.patient_id}')\n",
    "            print(f'session id: {data_loader.session_id}')\n",
    "            print(f'number of epochs: {epochs_data_session.shape[0]}')\n",
    "            print(f'number of channels: {epochs_data_session.shape[1]}')\n",
    "            print(f'number of time samples: {epochs_data_session.shape[2]}')\n",
    "\n",
    "    return data_patients, labels_patients, patients_id, sessions_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [03:23<00:00,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients: 14\n",
      "size of one epoch: (38, 37, 3073)\n",
      "CPU times: total: 1min 59s\n",
      "Wall time: 3min 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_patients, labels_patients, patients_id, sessions_id= preproc(FILE_PATH_LIST[:NUMBER_OF_SESSIONS])\n",
    "print(f'number of patients: {len(data_patients)}')\n",
    "print(f'size of one epoch: {data_patients[0][0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pipeline definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = Covariances(estimator='oas')\n",
    "ts = TangentSpace()\n",
    "ss = StandardScaler()\n",
    "cl = SVC()\n",
    "pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Cov&#x27;, Covariances(estimator=&#x27;oas&#x27;)),\n",
       "                (&#x27;TangentSpace&#x27;, TangentSpace()),\n",
       "                (&#x27;StandardScaler&#x27;, StandardScaler()), (&#x27;Classifier&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Cov&#x27;, Covariances(estimator=&#x27;oas&#x27;)),\n",
       "                (&#x27;TangentSpace&#x27;, TangentSpace()),\n",
       "                (&#x27;StandardScaler&#x27;, StandardScaler()), (&#x27;Classifier&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Covariances</label><div class=\"sk-toggleable__content\"><pre>Covariances(estimator=&#x27;oas&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TangentSpace</label><div class=\"sk-toggleable__content\"><pre>TangentSpace()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Cov', Covariances(estimator='oas')),\n",
       "                ('TangentSpace', TangentSpace()),\n",
       "                ('StandardScaler', StandardScaler()), ('Classifier', SVC())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(data_patients)):\n",
    "    for j in range(len(data_patients[i])):\n",
    "        X_train.append(data_patients[i][j])\n",
    "        y_train.append(labels_patients[i][j])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = cross_val_score(pipeline, X_train, y_train, cv=KFold(n_splits=N_SPLIT, random_state=RANDOM_STATE, shuffle=True)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8367685529395567"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./../../src/classif/models/model_riemann_SVC_v1.0.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_SAVE = './../../src/classif/models/'\n",
    "NAME_MODEL = 'model_riemann_SVC_v1.0.joblib'\n",
    "\n",
    "model_info = {\n",
    "    'pipeline': pipeline,\n",
    "    'additional_info': {\n",
    "        'aim': 'Binary classification of EEG signals to detect movement',\n",
    "        'date_of_training': '15-02-2024',\n",
    "        'data_preprocessing_details': 'StandardScaler, Covariances with OAS estimator, TangentSpace mapping',\n",
    "        'model_parameters': cl.get_params(),\n",
    "        'preprocessing_parameters': {\n",
    "            'FMIN': FMIN,\n",
    "            'FMAX': FMAX,\n",
    "            'EPOCHS_TMIN': EPOCHS_TMIN,\n",
    "            'EPOCHS_TMAX': EPOCHS_TMAX,\n",
    "            'EPOCHS_EMPTY_FROM_MVT_TMINS': EPOCHS_EMPTY_FROM_MVT_TMINS,\n",
    "            'BINARY_CLASSIFICATION': BINARY_CLASSIFICATION,\n",
    "            'RANDOM_STATE': RANDOM_STATE,\n",
    "            'N_SPLIT': N_SPLIT,\n",
    "            'NUMBER_OF_SESSIONS': NUMBER_OF_SESSIONS\n",
    "        },\n",
    "        'model_performance': {\n",
    "            'accuracy_train': accuracy_train,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "dump(model_info, PATH_SAVE + NAME_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions of train / validation\n",
    "1. test on the same patients and same sessions as the training -> A\n",
    "2. test on the same patients but different sessions -> B\n",
    "3. test on different patients -> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def train_test_A(data_patients, labels_patients, pipeline, verbose=False):\n",
    "    \"\"\"Train and test on on same patients, same sessions (different epochs)\"\"\"\n",
    "\n",
    "    # Creating folds\n",
    "    # split_folds = [patient1, patient2, ...] dtype = list\n",
    "    # patient1 = [session1_fold, session2_fold, ...] dtype = KFold\n",
    "    split_folds = []\n",
    "    i = 0\n",
    "    for patient in range(len(data_patients)):\n",
    "        split_folds.append([])\n",
    "        for session in range(len(data_patients[patient])):\n",
    "            random_state = RANDOM_STATE + i\n",
    "            cv = KFold(n_splits=N_SPLIT, shuffle=True, random_state=random_state)\n",
    "            split_folds[patient].append(cv.split(data_patients[patient][session]))\n",
    "            i+=1\n",
    "\n",
    "    # Training and testing\n",
    "    scores = []\n",
    "    for _ in range(N_SPLIT):\n",
    "        X_train, y_train = [], []\n",
    "        X_test, y_test = [], []\n",
    "        for patient in range(len(data_patients)):\n",
    "            for session in range(len(data_patients[patient])):\n",
    "                train_index, test_index = next(split_folds[patient][session])\n",
    "                X_train.append(data_patients[patient][session][train_index])\n",
    "                y_train.append(labels_patients[patient][session][train_index])\n",
    "                X_test.append(data_patients[patient][session][test_index])\n",
    "                y_test.append(labels_patients[patient][session][test_index])\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        scores.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        if verbose:\n",
    "            print(f'balanced accuracy {scores[-1]}')\n",
    "\n",
    "    if verbose:\n",
    "        print(f'mean of balance accuracy {np.mean(scores)}')\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_B(data_patients, labels_patients, pipeline, verbose=False):\n",
    "    \"\"\"Train and test on same patients, different sessions (different epochs)\"\"\"\n",
    "    \n",
    "    # Creating folds\n",
    "    # split_folds = [patient1, patient2, ...] dtype = list\n",
    "    # patient1 = [all_session_fold1, all_session_fold2, ...] dtype = tuple\n",
    "    # all_session_fold1 = (train_idx, test_idx) dtype = list\n",
    "    split_folds = []\n",
    "    i = 0\n",
    "    for patient in range(len(data_patients)):\n",
    "        split_folds.append([])\n",
    "        for split in range(N_SPLIT):\n",
    "            if len(data_patients[patient]) < 2:\n",
    "                test_idx = []\n",
    "                train_idx = [0]\n",
    "            else:\n",
    "                shuffle_idx = np.arange(len(data_patients[patient]))\n",
    "                np.random.RandomState(RANDOM_STATE+i).shuffle(shuffle_idx)\n",
    "                test_idx = [shuffle_idx[-1]]\n",
    "                train_idx = list(shuffle_idx[:-1])\n",
    "            split_folds[-1].append((train_idx, test_idx))\n",
    "            i+=1\n",
    "\n",
    "    # Training and testing\n",
    "    scores = []\n",
    "    for fold in range(N_SPLIT):\n",
    "        X_train, y_train = [], []\n",
    "        X_test, y_test = [], []\n",
    "        for patient in range(len(data_patients)):\n",
    "            for session in split_folds[patient][fold][0]:\n",
    "                X_train.append(data_patients[patient][session])\n",
    "                y_train.append(labels_patients[patient][session])\n",
    "            for session in split_folds[patient][fold][1]:\n",
    "                X_test.append(data_patients[patient][session])\n",
    "                y_test.append(labels_patients[patient][session])\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "        X_test = np.concatenate(X_test, axis=0)\n",
    "        y_test = np.concatenate(y_test, axis=0)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        scores.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        if verbose:\n",
    "            print(f'balanced accuracy {scores[-1]}')\n",
    "        \n",
    "    if verbose:\n",
    "        print(f'mean of balance accuracy {np.mean(scores)}')\n",
    "    \n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_C(data_patients, labels_patients, pipeline, verbose=False):\n",
    "    \"\"\"Train and test on different patients and different sessions\"\"\"\n",
    "    cv = KFold(n_splits=N_SPLIT, shuffle=True, random_state=RANDOM_STATE)\n",
    "    split_folds = cv.split(data_patients)\n",
    "    scores = []\n",
    "    i = 0\n",
    "    for train_patient_idx, test_patient_idx in split_folds:\n",
    "        train_data = np.concatenate([data_patients[i][j] for i in train_patient_idx for j in range(len(data_patients[i]))], axis=0)\n",
    "        train_labels = np.concatenate([labels_patients[i][j] for i in train_patient_idx for j in range(len(data_patients[i]))], axis=0)\n",
    "        test_data = np.concatenate([data_patients[i][j] for i in test_patient_idx for j in range(len(data_patients[i]))], axis=0)\n",
    "        test_labels = np.concatenate([labels_patients[i][j] for i in test_patient_idx for j in range(len(data_patients[i]))], axis=0)\n",
    "\n",
    "        # Shuffle train test\n",
    "        train_idx = np.arange(len(train_data))\n",
    "        np.random.RandomState(RANDOM_STATE+i).shuffle(train_idx)\n",
    "        train_data = train_data[train_idx]\n",
    "        train_labels = train_labels[train_idx]\n",
    "        test_idx = np.arange(len(test_data))\n",
    "        np.random.RandomState(RANDOM_STATE+i).shuffle(test_idx)\n",
    "        test_data = test_data[test_idx]\n",
    "        test_labels = test_labels[test_idx]\n",
    "        i+=1\n",
    "\n",
    "        # Train\n",
    "        pipeline.fit(train_data, train_labels)\n",
    "        y_pred = pipeline.predict(test_data)\n",
    "        scores.append(balanced_accuracy_score(test_labels, y_pred))\n",
    "        if verbose:\n",
    "            print(f'balanced accuracy {scores[-1]}')\n",
    "\n",
    "    if verbose:\n",
    "        print(f'mean of balance accuracy {np.mean(scores)}')\n",
    "\n",
    "    return np.mean(scores)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_X(data_patients, labels_patients, pipeline, verbose=False):\n",
    "    \"\"\"Train and test on all epoch data (patient, session, epoch shuffled) different epochs in test and train\"\"\"\n",
    "    epochs_data_collapsed = np.concatenate([np.concatenate(data_patients[i], axis=0) for i in range(len(data_patients))], axis=0)\n",
    "    labels_collapsed = np.concatenate([np.concatenate(labels_patients[i], axis=0) for i in range(len(data_patients))], axis=0)\n",
    "    cv = KFold(n_splits=N_SPLIT, shuffle=True, random_state=RANDOM_STATE)\n",
    "    scores = cross_val_score(pipeline, epochs_data_collapsed, labels_collapsed, cv=cv, scoring='balanced_accuracy')\n",
    "    if verbose:\n",
    "        print(f'mean of balance accuracy {np.mean(scores)}')\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Little inside on the cross validation split and folds for each tester (A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folds for test A :\n",
    "Creating folds of epochs for each session of each patient ensuring different suffled fold for each session. 4 folds for each session.\\\n",
    "test_size = 0.2 (epochs in test set for each session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0,  1,  2,  3,  5,  7,  8,  9, 10, 11, 12, 14, 16, 17, 18, 19, 20,\n",
       "         21, 22, 23, 25, 28, 29, 31, 32, 34, 35, 37]),\n",
       "  array([ 4,  6, 13, 15, 24, 26, 27, 30, 33, 36])),\n",
       " (array([ 1,  2,  3,  4,  6,  7, 10, 11, 13, 14, 15, 18, 20, 21, 22, 23, 24,\n",
       "         26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37]),\n",
       "  array([ 0,  5,  8,  9, 12, 16, 17, 19, 25, 32])),\n",
       " (array([ 0,  4,  5,  6,  7,  8,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "         22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 36]),\n",
       "  array([ 1,  2,  3, 11, 21, 29, 34, 35, 37])),\n",
       " (array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 11, 12, 13, 15, 16, 17, 19, 21,\n",
       "         24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37]),\n",
       "  array([ 7, 10, 14, 18, 20, 22, 23, 28, 31]))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_folds = []\n",
    "i = 0\n",
    "for patient in range(len(data_patients)):\n",
    "    split_folds.append([])\n",
    "    for session in range(len(data_patients[patient])):\n",
    "        random_state = RANDOM_STATE + i\n",
    "        cv = KFold(n_splits=N_SPLIT, shuffle=True, random_state=random_state)\n",
    "        split_folds[patient].append(cv.split(data_patients[patient][session]))\n",
    "        i+=1\n",
    "\n",
    "list(split_folds[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folds for test B:\n",
    "Creating folds of sessions for each patient ensuring different suffled fold for each patient. 4 folds for each patient.\\\n",
    "test_size  = 1 or 0 (sessions in test set for each patient) \\\n",
    "train_size =   number of sessions for one patient - test_size\n",
    "- if number of sessions for one patient = 1 -> test_size = 0 session\n",
    "- if number of sessions for one patient > 1 -> test_size = 1 session \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[([1], [0]), ([1], [0]), ([1], [0]), ([0], [1])],\n",
       " [([0], [1]), ([0], [1]), ([1], [0]), ([1], [0])],\n",
       " [([1], [0]), ([1], [0]), ([0], [1]), ([0], [1])],\n",
       " [([0], [1]), ([0], [1]), ([0], [1]), ([0], [1])],\n",
       " [([0], [1]), ([0], [1]), ([0], [1]), ([0], [1])],\n",
       " [([1], [0]), ([1], [0]), ([1], [0]), ([1], [0])],\n",
       " [([1], [0]), ([0], [1]), ([0], [1]), ([1], [0])],\n",
       " [([1], [0]), ([0], [1]), ([1], [0]), ([1], [0])],\n",
       " [([0, 1], [2]), ([1, 2], [0]), ([0, 2], [1]), ([1, 2], [0])],\n",
       " [([0], [1]), ([0], [1]), ([0], [1]), ([0], [1])],\n",
       " [([0], [1]), ([1], [0]), ([1], [0]), ([1], [0])],\n",
       " [([1], [0]), ([1], [0]), ([1], [0]), ([0], [1])],\n",
       " [([0], [1]), ([1], [0]), ([1], [0]), ([0], [1])],\n",
       " [([0], []), ([0], []), ([0], []), ([0], [])]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_folds = []\n",
    "i = 0\n",
    "for patient in range(len(data_patients)):\n",
    "    split_folds.append([])\n",
    "    for split in range(N_SPLIT):\n",
    "        if len(data_patients[patient]) < 2:\n",
    "            test_idx = []\n",
    "            train_idx = [0]\n",
    "        else:\n",
    "            shuffle_idx = np.arange(len(data_patients[patient]))\n",
    "            np.random.RandomState(RANDOM_STATE+i).shuffle(shuffle_idx)\n",
    "            test_idx = [shuffle_idx[-1]]\n",
    "            train_idx = list(shuffle_idx[:-1])\n",
    "        split_folds[-1].append((train_idx, test_idx))\n",
    "        i+=1\n",
    "\n",
    "list(split_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folds for test C:\n",
    "Creating folds of patients ensuring different suffled fold for each patient. 4 folds of patients in total.\\\n",
    "test_size  = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=N_SPLIT, shuffle=True, random_state=RANDOM_STATE)\n",
    "split_folds = cv.split(data_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 1,  2,  3,  4,  5,  6,  7,  8, 10, 13]), array([ 0,  9, 11, 12])),\n",
       " (array([ 0,  3,  4,  6,  7,  9, 10, 11, 12, 13]), array([1, 2, 5, 8])),\n",
       " (array([ 0,  1,  2,  3,  5,  6,  8,  9, 10, 11, 12]), array([ 4,  7, 13])),\n",
       " (array([ 0,  1,  2,  4,  5,  7,  8,  9, 11, 12, 13]), array([ 3,  6, 10]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(split_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test on the same patients and same sessions as training (differents epochs, cross validation) -> A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7773747107223659\n"
     ]
    }
   ],
   "source": [
    "cov = Covariances(estimator='oas')\n",
    "ts = TangentSpace()\n",
    "ss = StandardScaler()\n",
    "cl = LogisticRegression()\n",
    "pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "score = train_test_A(data_patients, labels_patients, pipeline, verbose=False)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 5s\n",
      "Wall time: 3min 6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.777375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.628792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.803127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.771442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  balanced_accuracy\n",
       "0          LogisticRegression           0.777375\n",
       "1                         SVC           0.837434\n",
       "2  LinearDiscriminantAnalysis           0.628792\n",
       "3      RandomForestClassifier           0.803127\n",
       "4          AdaBoostClassifier           0.771442"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier = [LogisticRegression(), SVC(), LinearDiscriminantAnalysis(), RandomForestClassifier(), AdaBoostClassifier()]\n",
    "balanced_accuracy = []\n",
    "for cl in classifier:\n",
    "    cov = Covariances(estimator='oas')\n",
    "    ts = TangentSpace()\n",
    "    ss = StandardScaler()\n",
    "    pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "    score = train_test_A(data_patients, labels_patients, pipeline)\n",
    "    balanced_accuracy.append(score)\n",
    "\n",
    "df = pd.DataFrame({'classifier': ['LogisticRegression', 'SVC', 'LinearDiscriminantAnalysis', 'RandomForestClassifier', 'AdaBoostClassifier'], 'balanced_accuracy': balanced_accuracy})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test on the same patients but different sessions (differents epochs, cross validation) -> B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.782\n",
      "balanced accuracy 0.7559523809523809\n",
      "balanced accuracy 0.7480314960629921\n",
      "balanced accuracy 0.762\n",
      "mean of balance accuracy 0.7619959692538433\n",
      "0.7619959692538433\n",
      "CPU times: total: 5.06 s\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cov = Covariances(estimator='oas')\n",
    "ts = TangentSpace()\n",
    "ss = StandardScaler()\n",
    "cl = LogisticRegression()\n",
    "pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "score = train_test_B(data_patients, labels_patients, pipeline, verbose=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.9 s\n",
      "Wall time: 2min 28s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.761996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.794267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.635699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.771374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.722130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  balanced_accuracy\n",
       "0          LogisticRegression           0.761996\n",
       "1                         SVC           0.794267\n",
       "2  LinearDiscriminantAnalysis           0.635699\n",
       "3      RandomForestClassifier           0.771374\n",
       "4          AdaBoostClassifier           0.722130"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier = [LogisticRegression(), SVC(), LinearDiscriminantAnalysis(), RandomForestClassifier(), AdaBoostClassifier()]\n",
    "balanced_accuracy = []\n",
    "for cl in classifier:\n",
    "    cov = Covariances(estimator='oas')\n",
    "    ts = TangentSpace()\n",
    "    ss = StandardScaler()\n",
    "    pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "    score = train_test_B(data_patients, labels_patients, pipeline)\n",
    "    balanced_accuracy.append(score)\n",
    "\n",
    "df = pd.DataFrame({'classifier': ['LogisticRegression', 'SVC', 'LinearDiscriminantAnalysis', 'RandomForestClassifier', 'AdaBoostClassifier'], 'balanced_accuracy': balanced_accuracy})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test on different patients (differents epochs, cross validation) -> C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.6566666666666667\n",
      "balanced accuracy 0.7162162162162162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy 0.7228260869565217\n",
      "balanced accuracy 0.5758928571428572\n",
      "mean of balance accuracy 0.6679004567455654\n",
      "0.6679004567455654\n",
      "CPU times: total: 7.45 s\n",
      "Wall time: 26.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cov = Covariances(estimator='oas')\n",
    "ts = TangentSpace()\n",
    "ss = StandardScaler()\n",
    "cl = LogisticRegression()\n",
    "pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "score = train_test_C(data_patients, labels_patients, pipeline, verbose=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 8s\n",
      "Wall time: 3min 10s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.667900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.646585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.552237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.644723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.624352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  balanced_accuracy\n",
       "0          LogisticRegression           0.667900\n",
       "1                         SVC           0.646585\n",
       "2  LinearDiscriminantAnalysis           0.552237\n",
       "3      RandomForestClassifier           0.644723\n",
       "4          AdaBoostClassifier           0.624352"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier = [LogisticRegression(), SVC(), LinearDiscriminantAnalysis(), RandomForestClassifier(), AdaBoostClassifier()]\n",
    "balanced_accuracy = []\n",
    "for cl in classifier:\n",
    "    cov = Covariances(estimator='oas')\n",
    "    ts = TangentSpace()\n",
    "    ss = StandardScaler()\n",
    "    pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "    score = train_test_C(data_patients, labels_patients, pipeline)\n",
    "    balanced_accuracy.append(score)\n",
    "\n",
    "df = pd.DataFrame({'classifier': ['LogisticRegression', 'SVC', 'LinearDiscriminantAnalysis', 'RandomForestClassifier', 'AdaBoostClassifier'], 'balanced_accuracy': balanced_accuracy})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test on all epochs shuffled (differents epochs, cross validation) -> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of balance accuracy 0.7819129027993258\n",
      "0.7819129027993258\n",
      "CPU times: total: 9.34 s\n",
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cov = Covariances(estimator='oas')\n",
    "ts = TangentSpace()\n",
    "ss = StandardScaler()\n",
    "cl = LogisticRegression()\n",
    "pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "score = train_test_X(data_patients, labels_patients, pipeline, verbose=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Documents\\Scolaires\\SUPAERO\\3A\\PIE\\PIE_2023\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 9s\n",
      "Wall time: 3min 20s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.620214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.804028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.757750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  balanced_accuracy\n",
       "0          LogisticRegression           0.781913\n",
       "1                         SVC           0.838495\n",
       "2  LinearDiscriminantAnalysis           0.620214\n",
       "3      RandomForestClassifier           0.804028\n",
       "4          AdaBoostClassifier           0.757750"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "classifier = [LogisticRegression(), SVC(), LinearDiscriminantAnalysis(), RandomForestClassifier(), AdaBoostClassifier()]\n",
    "balanced_accuracy = []\n",
    "for cl in classifier:\n",
    "    cov = Covariances(estimator='oas')\n",
    "    ts = TangentSpace()\n",
    "    ss = StandardScaler()\n",
    "    pipeline = Pipeline([('Cov', cov), ('TangentSpace', ts), ('StandardScaler', ss), ('Classifier', cl)])\n",
    "    score = train_test_X(data_patients, labels_patients, pipeline)\n",
    "    balanced_accuracy.append(score)\n",
    "\n",
    "df = pd.DataFrame({'classifier': ['LogisticRegression', 'SVC', 'LinearDiscriminantAnalysis', 'RandomForestClassifier', 'AdaBoostClassifier'], 'balanced_accuracy': balanced_accuracy})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
